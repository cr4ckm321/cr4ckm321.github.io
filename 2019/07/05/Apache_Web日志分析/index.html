<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="author" content="vQAQv"><meta name="description" content="喜欢电影，喜欢美食，喜欢旅游，也喜欢你💖~"><link rel="icon" href="/favicon.png"><title>Web日志安全分析技巧(转) - vQAQv's blog | Just Do It!</title><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/js/fancybox/jquery.fancybox.min.css"><!--[if lt IE 9]><script>(function(a,b){a="abbr article aside audio bdi canvas data datalist details dialog figcaption figure footer header hgroup main mark meter nav output progress section summary template time video".split(" ");for(b=a.length-1;b>=0;b--)document.createElement(a[b])})()</script><![endif]--><script src="/js/jquery-3.1.1.min.js"></script><script src="/js/fancybox/jquery.fancybox.min.js"></script></head><body style="opacity:1"><header class="head"><h1 class="head-title u-fl"><a href="/">vQAQv's blog | Just Do It!</a></h1><nav class="head-nav u-fr"><ul class="head-nav__list"><li class="head-nav__item"><a class="head-nav__link" href="/archives">Archives</a></li><li class="head-nav__item"><a class="head-nav__link" href="/about">About Me</a></li></ul></nav></header><main class="main"><article class="post"><header class="post__head"> <time class="post__time" datetime="2019-07-04T16:00:00.000Z">七月 5, 2019</time><h1 class="post__title"><a href="/2019/07/05/Apache_Web日志分析/">Web日志安全分析技巧(转)</a></h1><div class="post__main echo"><h1 id="Web日志安全分析技巧"><a href="#Web日志安全分析技巧" class="headerlink" title="Web日志安全分析技巧"></a><p style="text-align: center;">Web日志安全分析技巧</p></h1><p>Web访问日志记录了Web服务器接收处理请求及运行时错误等各种原始信息。通过对WEB日志进行的安全分析，不仅可以帮助我们定位攻击者，还可以帮助我们还原攻击路径，找到网站存在的安全漏洞并进行修复。<br><a id="more"></a></p>
<h2 id="0x01-Web日志"><a href="#0x01-Web日志" class="headerlink" title="0x01  Web日志"></a>0x01  Web日志</h2><p>我们来看一条Apache的访问日志：<br><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">127</span>.<span class="number">0</span>.<span class="number">0</span>.<span class="number">1</span> - - [<span class="number">11</span>/Jun/<span class="number">2018</span>:<span class="number">12</span>:<span class="number">47</span>:<span class="number">22</span> +<span class="number">0800</span>] "GET /login.html HTTP/<span class="number">1</span>.<span class="number">1</span>" <span class="number">200</span> <span class="number">786</span> "-" "Mozilla/<span class="number">5</span>.<span class="number">0</span> (Windows NT <span class="number">10</span>.<span class="number">0</span>; WOW64) AppleWebKit/<span class="number">537</span>.<span class="number">36</span> (KHTML, like Gecko) Chrome/<span class="number">66</span>.<span class="number">0</span>.<span class="number">3359</span>.<span class="number">139</span> Safari/<span class="number">537</span>.<span class="number">36</span>"</span><br></pre></td></tr></table></figure></p>
<p>通过这条Web访问日志，我们可以清楚的得知用户在什么IP、什么时间、用什么操作系统、什么浏览器的情况下访问了你网站的哪个页面，是否访问成功。</p>
<p>本文通过介绍Web日志安全分析时的思路和常用的一些技巧。</p>
<h2 id="0x02-日志分析技巧"><a href="#0x02-日志分析技巧" class="headerlink" title="0x02 日志分析技巧"></a>0x02 日志分析技巧</h2><p>在对WEB日志进行安全分析时，一般可以按照两种思路展开，逐步深入，还原整个攻击过程。</p>
<p>第一种：确定入侵的时间范围，以此为线索，查找这个时间范围内可疑的日志，进一步排查，最终确定攻击者，还原攻击过程。</p>
<p>第二种：攻击者在入侵网站后，通常会留下后门维持权限，以方便再次访问，我们可以找到该文件，并以此为线索来展开分析。</p>
<p>常用分析工具：</p>
<p>Window下，推荐用 EmEditor 进行日志分析，支持大文本，搜索效率还不错。</p>
<p>Linux下，使用Shell命令组合查询分析。</p>
<p>Shell+Linux命令实现日志分析，一般结合grep、awk等命令等实现了几个常用的日志分析统计技巧。</p>
<p>Apache日志分析技巧：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">1、列出当天访问次数最多的IP命令：</span><br><span class="line">cut -d- -f 1 log_file|uniq -c | sort -rn | head -20</span><br><span class="line"></span><br><span class="line">2、查看当天有多少个IP访问：</span><br><span class="line">awk <span class="string">'&#123;print $1&#125;'</span> log_file|sort|uniq|wc -l</span><br><span class="line"></span><br><span class="line">3、查看某一个页面被访问的次数：</span><br><span class="line">grep <span class="string">"/index.php"</span> log_file | wc -l</span><br><span class="line"></span><br><span class="line">4、查看每一个IP访问了多少个页面：</span><br><span class="line">awk <span class="string">'&#123;++S[$1]&#125; END &#123;for (a in S) print a,S[a]&#125;'</span> log_file</span><br><span class="line"></span><br><span class="line">5、将每个IP访问的页面数进行从小到大排序：</span><br><span class="line">awk <span class="string">'&#123;++S[$1]&#125; END &#123;for (a in S) print S[a],a&#125;'</span> log_file | sort -n</span><br><span class="line"></span><br><span class="line">6、查看某一个IP访问了哪些页面：</span><br><span class="line">grep ^111.111.111.111 log_file| awk <span class="string">'&#123;print $1,$7&#125;'</span></span><br><span class="line"></span><br><span class="line">7、去掉搜索引擎统计当天的页面：</span><br><span class="line">awk <span class="string">'&#123;print $12,$1&#125;'</span> log_file | grep ^\<span class="string">"Mozilla | awk '&#123;print <span class="variable">$2</span>&#125;' |sort | uniq | wc -l</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">8、查看2018年6月21日14时这一个小时内有多少IP访问:</span></span><br><span class="line"><span class="string">awk '&#123;print <span class="variable">$4</span>,<span class="variable">$1</span>&#125;' log_file | grep 21/Jun/2018:14 | awk '&#123;print <span class="variable">$2</span>&#125;'| sort | uniq | wc -l</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">9、在未有系统，且日志量不大时可以采用对accesslog进行uri、ip等top10罗列，具体作用用于分析是否存在恶意ip、哪个接口访问过高等维度。</span></span><br><span class="line"><span class="string">awk '&#123;print <span class="variable">$7</span>&#125;' access.log | sort -n |uniq -c | sort -rn | head -n 10</span></span><br></pre></td></tr></table></figure></p>
<h2 id="0x03-日志分析案例"><a href="#0x03-日志分析案例" class="headerlink" title="0x03 日志分析案例"></a>0x03 日志分析案例</h2><p>Web日志分析实例：通过nginx代理转发到内网某服务器，内网服务器某站点目录下被上传了多个图片木马，虽然II7下不能解析，但还是想找出谁通过什么路径上传的。</p>
<p>在这里，我们遇到了一个问题：由于设置了代理转发，只记录了代理服务器的ip，并没有记录访问者IP？这时候，如何去识别不同的访问者和攻击源呢？</p>
<p>这是管理员日志配置不当的问题，但好在我们可以通过浏览器指纹来定位不同的访问来源，还原攻击路径。</p>
<p>1、定位攻击源</p>
<p>首先访问图片木马的记录，只找到了一条，由于所有访问日志只记录了代理IP，并不能通过IP来还原攻击路径，这时候，可以利用浏览器指纹来定位。</p>
<p>浏览器指纹：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mozilla/4.0+(compatible;+MSIE+7.0;+Windows+NT+6.1;+WOW64;+Trident/7.0;+SLCC2;+.NET+CLR+2.0.50727;+.NET+CLR+3.5.30729;+.NET+CLR+3.0.30729;+.NET4.0C;+.NET4.0E)</span><br></pre></td></tr></table></figure></p>
<p>2、搜索相关日志记录</p>
<p>通过筛选与该浏览器指纹有关的日志记录，可以清晰地看到攻击者的攻击路径。</p>
<p>3、对找到的访问日志进行解读，攻击者大致的访问路径如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">A、攻击者访问首页和登录页</span><br><span class="line">B、攻击者访问MsgSjlb.aspx和MsgSebd.aspx</span><br><span class="line">C、攻击者访问Xzuser.aspx</span><br><span class="line">D、攻击者多次POST（怀疑通过这个页面上传模块缺陷）</span><br><span class="line">E、攻击者访问了图片木马</span><br></pre></td></tr></table></figure></p>
<p>打开网站，访问Xzuser.aspx，确认攻击者通过该页面的进行文件上传了图片木马，同时，发现网站了存在越权访问漏洞，攻击者访问特定URL，无需登录即可进入后台界面。通过日志分析找到网站的漏洞位置并进行修复。</p>
<h2 id="0x04-日志统计分析技巧"><a href="#0x04-日志统计分析技巧" class="headerlink" title="0x04 日志统计分析技巧"></a>0x04 日志统计分析技巧</h2><blockquote>
<p>查看Auth.log,检查SSH是否被扫</p>
</blockquote>
<p>查看用密码登陆成功的IP地址及次数<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep <span class="string">"Accepted password for root"</span> /var/<span class="built_in">log</span>/auth.log | awk <span class="string">'&#123;print $11&#125;'</span> | sort | uniq -c | sort -nr | more</span><br></pre></td></tr></table></figure></p>
<p>查看用密码登陆失败的IP地址及次数<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep <span class="string">"Failed password for root"</span> /var/<span class="built_in">log</span>/auth.log | awk <span class="string">'&#123;print $11&#125;'</span> | sort | uniq -c | sort -nr | more</span><br></pre></td></tr></table></figure></p>
<p>统计爬虫：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -E <span class="string">'Googlebot|Baiduspider'</span>  /www/logs/access.2019-02-23.log | awk <span class="string">'&#123; print $1 &#125;'</span> | sort | uniq</span><br></pre></td></tr></table></figure></p>
<p>统计浏览器：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /www/logs/access.2019-02-23.log | grep -v -E <span class="string">'MSIE|Firefox|Chrome|Opera|Safari|Gecko|Maxthon'</span> | sort | uniq -c | sort -r -n | head -n 100</span><br></pre></td></tr></table></figure></p>
<p>IP 统计：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">grep <span class="string">'23/May/2019'</span> /www/logs/access.2019-02-23.log | awk <span class="string">'&#123;print $1&#125;'</span> | awk -F<span class="string">'.'</span> <span class="string">'&#123;print $1"."$2"."$3"."$4&#125;'</span> | sort | uniq -c | sort -r -n | head -n 10</span><br><span class="line">   2206 219.136.134.13</span><br><span class="line">   1497 182.34.15.248</span><br><span class="line">   1431 211.140.143.100</span><br><span class="line">   1431 119.145.149.106</span><br><span class="line">   1427 61.183.15.179</span><br><span class="line">   1427 218.6.8.189</span><br><span class="line">   1422 124.232.150.171</span><br><span class="line">   1421 106.187.47.224</span><br><span class="line">   1420 61.160.220.252</span><br><span class="line">   1418 114.80.201.18</span><br></pre></td></tr></table></figure></p>
<p>统计网段：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /www/logs/access.2019-02-23.log | awk <span class="string">'&#123;print $1&#125;'</span> | awk -F<span class="string">'.'</span> <span class="string">'&#123;print $1"."$2"."$3".0"&#125;'</span> | sort | uniq -c | sort -r -n | head -n 200</span><br></pre></td></tr></table></figure></p>
<p>统计域名：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat  /www/logs/access.2019-02-23.log |awk <span class="string">'&#123;print $2&#125;'</span>|sort|uniq -c|sort -rn|more</span><br></pre></td></tr></table></figure></p>
<p>HTTP 状态：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat  /www/logs/access.2019-02-23.log |awk <span class="string">'&#123;print $9&#125;'</span>|sort|uniq -c|sort -rn|more</span><br><span class="line">5056585 304</span><br><span class="line">1125579 200</span><br><span class="line">   7602 400</span><br><span class="line">      5 301</span><br></pre></td></tr></table></figure></p>
<p>URL 统计：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat  /www/logs/access.2019-02-23.log |awk <span class="string">'&#123;print $7&#125;'</span>|sort|uniq -c|sort -rn|more</span><br></pre></td></tr></table></figure></p>
<p>文件流量统计：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat /www/logs/access.2019-02-23.log |awk <span class="string">'&#123;sum[$7]+=$10&#125;END&#123;for(i in sum)&#123;print sum[i],i&#125;&#125;'</span>|sort -rn|more</span><br><span class="line">grep <span class="string">' 200 '</span> /www/logs/access.2019-02-23.log |awk <span class="string">'&#123;sum[$7]+=$10&#125;END&#123;for(i in sum)&#123;print sum[i],i&#125;&#125;'</span>|sort -rn|more</span><br></pre></td></tr></table></figure></p>
<p>URL访问量统计：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /www/logs/access.2019-02-23.log | awk <span class="string">'&#123;print $7&#125;'</span> | egrep <span class="string">'\?|&amp;'</span> | sort | uniq -c | sort -rn | more</span><br></pre></td></tr></table></figure></p>
<p>脚本运行速度：</p>
<p>查出运行速度最慢的脚本<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -v 0$ /www/logs/access.2019-02-23.log | awk -F <span class="string">'\" '</span> <span class="string">'&#123;print $4" " $1&#125;'</span> web.log | awk <span class="string">'&#123;print $1" "$8&#125;'</span> | sort -n -k 1 -r | uniq &gt; /tmp/slow_url.txt</span><br></pre></td></tr></table></figure></p>
<p>IP, URL 抽取：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tail -f /www/logs/access.2019-02-23.log | grep <span class="string">'/test.html'</span> | awk <span class="string">'&#123;print $1" "$7&#125;'</span></span><br></pre></td></tr></table></figure></p>
<ul>
<li>转载来源</li>
</ul>
<p><a href="https://mp.weixin.qq.com/s/CtnHy9X7_csTwrG5KJvDjg" target="_blank" rel="noopener">Bypass微信公众号-Web日志安全分析技巧</a></p>
</div></header><footer class="post__foot u-cf"><ul class="post__tag u-fl"><li class="post__tag__item"><a class="post__tag__link" href="/tags/日志分析/">日志分析</a></li></ul></footer></article><section class="reward"> <a class="btn-reward" href="#">Contact me</a><div class="reward-wrapper clearfix"><img src="/img/wechat.png" title="微信"></div></section></main><footer class="foot"><div class="foot-copy">&copy; 2016-2019 vQAQv</div></footer><script src="/js/scroller.js"></script><script src="/js/main.js"></script></body></html>